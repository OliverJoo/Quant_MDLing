{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from alphalens.tears import (create_summary_tear_sheet,\n",
    "                             create_full_tear_sheet)\n",
    "\n",
    "from alphalens.utils import get_clean_factor_and_forward_returns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils4t import MultipleTimeSeriesCV, format_time\n",
    "sns.set_style('whitegrid')\n",
    "YEAR = 252\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1689358 entries, ('A', Timestamp('2010-01-04 00:00:00')) to ('ZION', Timestamp('2016-12-30 00:00:00'))\n",
      "Data columns (total 34 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   dollar_vol       1689358 non-null  float64\n",
      " 1   dollar_vol_rank  1689358 non-null  float64\n",
      " 2   rsi              1675904 non-null  float64\n",
      " 3   bb_high          1671099 non-null  float64\n",
      " 4   bb_low           1671097 non-null  float64\n",
      " 5   NATR             1675904 non-null  float64\n",
      " 6   ATR              1675904 non-null  float64\n",
      " 7   PPO              1665333 non-null  float64\n",
      " 8   MACD             1657645 non-null  float64\n",
      " 9   sector           1689358 non-null  int32  \n",
      " 10  r01              1689357 non-null  float64\n",
      " 11  r05              1689353 non-null  float64\n",
      " 12  r10              1689348 non-null  float64\n",
      " 13  r21              1689337 non-null  float64\n",
      " 14  r42              1689316 non-null  float64\n",
      " 15  r63              1689295 non-null  float64\n",
      " 16  r01dec           1689357 non-null  float64\n",
      " 17  r05dec           1689353 non-null  float64\n",
      " 18  r10dec           1689348 non-null  float64\n",
      " 19  r21dec           1689337 non-null  float64\n",
      " 20  r42dec           1689316 non-null  float64\n",
      " 21  r63dec           1689295 non-null  float64\n",
      " 22  r01q_sector      1689357 non-null  float64\n",
      " 23  r05q_sector      1689353 non-null  float64\n",
      " 24  r10q_sector      1689348 non-null  float64\n",
      " 25  r21q_sector      1689337 non-null  float64\n",
      " 26  r42q_sector      1689316 non-null  float64\n",
      " 27  r63q_sector      1689295 non-null  float64\n",
      " 28  r01_fwd          1689358 non-null  float64\n",
      " 29  r05_fwd          1689358 non-null  float64\n",
      " 30  r21_fwd          1689343 non-null  float64\n",
      " 31  year             1689358 non-null  int64  \n",
      " 32  month            1689358 non-null  int64  \n",
      " 33  weekday          1689358 non-null  int64  \n",
      "dtypes: float64(30), int32(1), int64(3)\n",
      "memory usage: 439.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = (pd.read_hdf('data/data.h5', 'model_data').sort_index().loc[idx[:, :'2016'], :])\n",
    "data.info(null_counts=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist() # extracting labels that contain _fwd\n",
    "\n",
    "tickers = data.index.get_level_values('symbol').unique()\n",
    "\n",
    "# predict 1, 5, 21 day returns\n",
    "lookaheads = [1, 5, 21]\n",
    "categoricals = ['year', 'month', 'sector', 'weekday']\n",
    "\n",
    "# set train period for 4.5y & test period 3, 1 months\n",
    "train_lengths = [int(4.5 * 252), 252]\n",
    "test_lengths = [63, 21]\n",
    "test_params = list(product(lookaheads, train_lengths, test_lengths))\n",
    "\n",
    "results_path = Path('results', 'us_stocks')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[1134, 252]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lengths"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [06:29<00:00, 32.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# Baseline: Linear Regression\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr_metrics = []\n",
    "\n",
    "# iterate over our three CV configuration parameters\n",
    "for lookahead, train_length, test_length in tqdm(test_params):\n",
    "    label = f'r{lookahead:02}_fwd'\n",
    "    df = pd.get_dummies(data.loc[:, features + [label]].dropna(), columns=categoricals, drop_first=True)\n",
    "    X, y = df.drop(label, axis=1), df[label]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits, test_period_length=test_length, lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    ic, preds = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=X)):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        preds.append(y_test.to_frame('y_true').assign(y_pred=y_pred))\n",
    "        ic.append(spearmanr(y_test, y_pred)[0])\n",
    "    preds = pd.concat(preds)\n",
    "    lr_metrics.append([lookahead, train_length, test_length, np.mean(ic),\n",
    "                       spearmanr(preds.y_true, preds.y_pred)[0]])\n",
    "\n",
    "columns = ['lookahead', 'train_length', 'test_length', 'ic_by_day', 'ic']\n",
    "lr_metrics = pd.DataFrame(lr_metrics, columns=columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, '')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1008x360 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAAFJCAYAAAChJA1XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvgklEQVR4nO3deXBUZaL+8aezkqQJsUFZhGBMCIMiQsCqURYRYQwpEPASTOAiM+C4DUQBIxiRQYhsCqNRwQKVQS5CYNA7XEBUdmEYkQwZZJXAJVIugGkZ0glk6/79waHv8MO2s3WfLN9PFSXp033eJx3D20+/55y2uFwulwAAAAAACjA7AAAAAADUFRQkAAAAADBQkAAAAADAQEECAAAAAAMFCQAAAAAMFCQAAAAAMASZHQCob/r166fXX39dd9xxhyRp+/bteu+991RYWKiysjJ16NBBU6ZMUevWra97bMeOHbV3717ZbLZqjx0cHKwmTZrI5XKpoqJC/fr109NPP62gIH6dAaCxq8kcJUl79+7VokWLdPbsWTVp0kTNmzfXH/7wB/Xo0cPn2b/44gvNmjVLGzZs0NSpU9WhQweNGzfO5+MC/z9eUQE18D//8z9avHixFi9erPbt28vlcmnJkiV65JFHtHHjRoWEhNT6mK+++qp74isuLtazzz6rOXPm6MUXX6z1sQAA9VdV56itW7dq7ty5mj9/vrp16yZJys3N1cSJEzVjxgzde++9ZnwbgN9xiB1QA3/605/0wgsvqH379pIki8Wixx57TGlpaSotLf3Zx7z22msaNmyYhgwZou3bt0uSfve73yk7O9t9n8WLF2v27Nlexw8PD9f06dOVnZ0th8Oh4uJiPffccxoxYoQeeOABPfTQQzp16pS+++47devWTYWFhZIkl8ulBx54QMeOHavpUwAAqKOqOkfNnz9f06ZNc5cjSeratasyMjI0f/58FRYWKiEhQefPn3dvHzFihHbu3KnS0lLNnj1bw4YN04MPPqipU6fK4XBIurKq9cwzz2jgwIH67LPPtH37dqWkpOihhx5S37599dprr/n2iQCqiIIEVNNPP/2kb7/9VgkJCdfcbrFYNHjwYFmt1p99XNu2bfXRRx/plVde0dSpU2W32zVq1CitXbtWkuR0OrV27VqlpKRUKkerVq1ktVp16tQp7dq1S5GRkVqzZo0++eQTde7cWStXrlSbNm109913a/369ZKkv//974qKitKvfvWrGjwDAIC6qqpz1E8//aTTp0/rrrvuum5fd999t/Ly8uR0OjVgwAD3XHLy5EmdP39evXv31pIlSxQYGKgPP/xQ69ev10033aRXX33VvY8OHTro448/Vv/+/fXee+9p7ty5+vDDD5Wdna0lS5bIbrf74FkAqodD7IBqCgi48v6C0+ms0uNSU1MlSfHx8YqNjdWBAwd03333KTMzU8eOHdPZs2fVtm1b3XrrrZXep8ViUVhYmBITE9WuXTutWLFC+fn52rdvn/udwFGjRumVV17RqFGjlJ2d7c4BAGh4qjtHlZeXX3fb1dUmi8Wi5ORkvfTSSxo3bpzWrVunhx56SAEBAdqxY4cKCwv1t7/9TZJUVlam5s2bu/dx9Rwmi8Wit99+Wzt27NCGDRt08uRJuVwuXbp0qVrfJ+ALrCAB1dSsWTPdcsst+uc//3ndtqefftrj4WtXJy3pyqFuQUFBCgwMVEpKiv7yl79o3bp1lV49kqRvv/1WxcXFio6O1gcffKAXXnhBTZo00eDBgzVo0CC5XC5J0j333KNLly5p79692r9/vwYOHFjF7xgAUF9UdY664YYbFBMTo3379l13/y+++EKxsbGKjIxUjx49VF5eroMHD2rDhg36j//4D0lXilhGRob++te/6q9//avWrl2r119/3b2P8PBwSVfOnR02bJgOHz6s2267Tc8995yCgoLccxVQF1CQgBoYP368Xn75ZeXn50uSKioqtGjRIh07dszjCtBHH30kSTp8+LDy8/N15513SpKSk5O1ZcsWHT58WAMGDKjU+BcvXtSsWbM0atQohYaGavfu3Ro2bJiSk5MVExOjbdu2qaKiQtKVd+1GjhypF154QYMGDVJoaGhNv30AQB1W1Tnq+eef1+zZs5Wbm+u+7cCBA5o7d66effZZ923JycmaNWuWOnbsqDZt2kiSevXqpZUrV6q0tFROp1MvvviiFi5ceN0Y+fn5cjgceuaZZ9SvXz/t27fP/RigruAQO6AGBg8eLJfLpUmTJqm8vFwlJSW6/fbbtXz5co9XsDtz5oyGDh0qi8WihQsXKioqSpLUvHlzde7cWbGxsQoODvY45rPPPqsmTZooMDBQFRUV+s1vfqMnn3xSkjR27FhNnz5dH374oQIDA3X77bfr66+/dj922LBhmjdvnh5++OHaexIAAHVSVeeoe++9V/PmzdPrr7+uH374QS6XS61atdK8efP061//2n2/oUOHauHChdcUoKeeekrz5s3TsGHDVFFRoU6dOmnq1KnXjdGxY0f17dtXAwcOVGRkpKKjoxUXF6f8/HyfXPkVqA6LizVNoE6w2+0aPny4Vq5c6fHzKWpq48aN+uijj/TOO+/4ZP8AAAD1HStIQB2wZs0aLVy4UE888YTPytHo0aP1448/6o033vDJ/gEAABoCVpAAAAAAwMBFGgAAAADA4LdD7JxOp2bMmKHjx48rJCREmZmZ7k92lqQ///nP2rhxo6QrJwmOHz9ely9fVnp6ugoKChQREaF58+bJZrP5KzIAAACARsZvK0hbtmxRaWmpsrOzNXnyZM2dO9e97cyZM1q/fr1Wr16tNWvWaPfu3Tp27JhWrVql+Ph4ffDBBxo6dKgWLVrkr7gAAAAAGiG/rSDl5OSod+/ekqSuXbvq0KFD7m2tWrXSO++8o8DAQElXPsU5NDRUOTk5evTRRyVJffr0qVRBys3N5fNdAMBkJSUl6tq1q9kx6iTmKQCoGzzNVX5bQXI4HLJare6vAwMDVV5eLkkKDg6WzWaTy+XSvHnzdNtttykmJkYOh0NNmzaVJEVERKiwsNBfcQEANUABAADUdZ7mKr+tIFmtVhUVFbm/djqdCgr6v+FLSkqUkZGhiIgI/fGPf7zuMUVFRYqMjPQ6TmhoqDp16lTL6QEAVXH06FGzI9RZzFMAUDd4mqv8toKUkJCgXbt2SbpyeEF8fLx7m8vl0lNPPaWOHTtq5syZ7kPtEhIStHPnTknSrl271L17d3/FBQAAANAI+W0FacCAAdqzZ49SUlLkcrk0e/ZsLVu2TNHR0XI6ndq3b59KS0v1+eefS5ImTZqk1NRUTZkyRampqQoODtaCBQv8FRcAAABAI+S3ghQQEKCZM2dec1tsbKz771999dXPPi4rK8unuQAAAADgKj4oFgAAAAAMFCQAAAAAMFCQAAAAAMBAQQIAAAAAAwUJAAAAAAx+u4od0FBs3rxZmzZt8tn+7Xa7JMlms/lsjKSkJCUmJvps/wAAAPUVBQmoYwoKCiT5tiABAADg51GQgCpKTEz06epLWlqaJD4DDAAAwAycgwQAAAAABgoSAAAAABgoSAAAAABgoCABAAAAgIGCBAAAAAAGChIAAAAAGChIAAAAAGCgIAEAAACAgYIEAAAAAAYKEgAAAAAYKEgAAAAAYKAgAQAAAICBggQAAAAABgoSAAAAABgoSAAAAABgoCABAAAAgCHI7AAAAAAAvNu8ebM2bdrkk33b7XZJks1m88n+JSkpKUmJiYk+239toSABAAAAjVxBQYEk3xak+oKCBAAAANQDiYmJPluBSUtLkyRlZWX5ZP/1CecgAQAAAICBggQAAAAABg6xQ4OUlZWlvLw8s2NUy4kTJyT931J3fRMXF1dvswMAAFCQ0CDl5eXp60P/ULS1wuwoVRbpskiSLp/+0uQkVfeNI9DsCAAAADVCQUKDFW2t0LQeDrNjNCqZ+61mRwAAAKgRzkECAAAAAAMFCQAAAAAMFCQAAAAAMFCQAAAAAMBAQQIAAAAAAwUJAAAAAAx+u8y30+nUjBkzdPz4cYWEhCgzM1Pt27e/5j52u12pqalav369QkND5XK51KdPH91yyy2SpK5du2ry5Mn+igwAAACgkfFbQdqyZYtKS0uVnZ2t3NxczZ07V4sXL3Zv//zzz7VgwQKdP3/efds333yj22+/XW+//ba/YgIAAABoxPx2iF1OTo569+4t6cpK0KFDh64NEhCgZcuWKSoqyn3b4cOHdfbsWY0ePVq///3vderUKX/FBQAAANAI+W0FyeFwyGq1ur8ODAxUeXm5goKuROjZs+d1j7nxxhv12GOPaeDAgdq/f7/S09O1bt26XxynpKRER48erd3wqHeKi4s5wc4kxcXF/A4Cv4B5CkBdVFxcLEn8+yQ/FiSr1aqioiL3106n012OPOncubMCAwMlST169NC5c+fkcrlksVg8PiY0NFSdOnWqndCot8LDw3XZ7BCNVHh4OL+DYIL9BcxTAOqi8PBwSWpU/z55mqv89iZ7QkKCdu3aJUnKzc1VfHy818e8+eabWr58uSTp2LFjat269S+WIwAAAACoCb+tIA0YMEB79uxRSkqKXC6XZs+erWXLlik6Olr333//zz7mscceU3p6unbu3KnAwEDNmTPHX3EBAAAANEJ+K0gBAQGaOXPmNbfFxsZed79t27a5/96sWTMtWbLE59kAQJI2b96sTZs2+WTfdrtdkmSz2Xyyf0lKSkpSYmKiz/YPAEBj4LeCBACNWUFBgSTfFiQAAFBzFCQAMCQmJvpsBSYtLU2SlJWV5ZP9AwCA2sGVkAEAAADAQEECAAAAAAMFCQAAAAAMFCQAAAAAMFCQAAAAAMBAQQIAAAAAAwUJAAAAAAwUJAAAAAAwUJAAAAAAwEBBAgAAAABDkNkBAKCysrKylJeXZ3aMajlx4oQkKS0tzeQk1RcXF1ev8wMAUBkUJAD1Rl5eng4cPiBFmZ2kGoz1+gPfHjA3R3VdMDsAAAD+QUECUL9ESc6+TrNTNDoBOzgiGwDQODDjAQAAAICBggQAAAAABgoSAAAAABgoSAAAAABgoCABAAAAgIGCBAAAAAAGChIAAAAAGChIAAAAAGCgIAEAAACAIcjsAABQWXa7XbogBezgvR2/uyDZw+xmpwAAwOd4lQEAAAAABlaQ0CDZ7XadLwxU5n6r2VEalfzCQN1o990qg81mU/6lfDn7On02Bn5ewI4A2Ww2s2MAAOBzrCABAAAAgIEVJDRINptN4RdPaloPh9lRGpXM/VY1YZUBAADUYxQkAAAAoBZkZWUpLy/P7BjVcuLECUlSWlqayUmqLy4urlbyU5AAAACAWpCXl6cDhw9IUWYnqQbjxJsD3x4wN0d1Xai9XVGQAAAAgNoSJS4mZILa/AgQLtIAAAAAAAYKEgAAAAAYvBak7du3X/P1pk2bfBYGAAAAAMzk8Ryk7du36x//+Ic2btyoAweunKxVUVGhbdu2KSkpyW8BAQAAAMBfPBakX/3qV7pw4YJCQ0MVExMjSbJYLBo0aJDfwgEAAACAP3ksSK1bt9awYcM0ZMgQBQRwqhIAAACAhs/rZb6XLl2qpUuXqkmTJu7bdu/eXeWBnE6nZsyYoePHjyskJESZmZlq3779Nfex2+1KTU3V+vXrFRoaqsuXLys9PV0FBQWKiIjQvHnzZLPZqjw2AAAAAFSG16WhjRs36vPPP9fu3bvdf6pjy5YtKi0tVXZ2tiZPnqy5c+des/3zzz/X2LFjdf78efdtq1atUnx8vD744AMNHTpUixYtqtbYAAAAAFAZXgtS27Ztr1k9qq6cnBz17t1bktS1a1cdOnTo2iABAVq2bJmioqJ+9jF9+vTR3r17a5wDAAAAADzxeohdWVmZBg8erPj4eFksFknSggULqjyQw+GQ1Wp1fx0YGKjy8nIFBV2J0LNnz599TNOmTSVJERERKiws9DpOSUmJjh49WuV8aFiKi4v5kC+TFBcX++x3sLi4WLpQu5+W7TeXjf/W/P0mc1yQim/w3c+2MWGeAhqu4uJisyM0arX1GsRrQfr9739f40EkyWq1qqioyP210+l0l6PKPKaoqEiRkZFexwkNDVWnTp1qFhb1Xnh4uPv1KPwrPDzcZ7+DXbp0UXh4uE/27WsnTpyQJHW4uYPJSarpZikuLq7SP1sKgGfMU0DDFR4eLv1kdorGq6qvQTzNVV4L0m233aalS5fq3Llzuu+++9SxY8fKp/w3CQkJ2r59u5KSkpSbm6v4+PhKPWbnzp3q0qWLdu3ape7du1drbAANQ1pamtkRqu1q9qysLJOTAACAX+L1OJWMjAy1a9dO+fn5atGihV544YVqDTRgwACFhIQoJSVFc+bM0fPPP69ly5Zp69atHh+TmpqqEydOKDU1VdnZ2Ro/fny1xgYAAACAyvC6gnThwgUNHz5c69evV0JCgpxOZ7UGCggI0MyZM6+5LTY29rr7bdu2zf33sLAw3m0FAAAA4DeVOtP55MmTkqQffvhBgYGBPg0EAAAAAGbxWpBeeOEFZWRk6MiRI0pLS9PUqVP9kQsAAAAA/M7rIXYdO3ZUdna2P7IAAAAAgKk8FqS0tDRlZWWpV69e123bvXu3T0MBAAAAgBk8FqSrF0fYvXu3iouLFR4errNnz6ply5Z+CwcAAAAA/uT1HKQ333xTb7/9tiTp5Zdf1pIlS3weCgAAAADM4LUgbdu2TZMmTZJ0ZVXp3y/DDQAAAAANideCZLFYVFpaKkkqKyuTy+XyeSgAAAAAMIPXq9ilpKRo8ODBio+P16lTp/Too4/6IxcAAAAA+J3XgpScnKz7779fZ86cUbt27WSz2fyRCwAAAAD8zmNBWrRokZ566ilNmjRJFovlmm0LFizweTAAAAAA8DePBclqtUqShg4dqiZNmvgtEAAAAACYxWNBWrdunYYPH66lS5fqvffe4+IMAAAAABo8jwWpd+/eevDBB3Xu3DklJiZKklwulywWi7Zu3eq3gAAAAADgLx4LUqtWrbRlyxa9+eabGj9+vD8zAQAAAIApPBakFStWqG3btvrss8/UrVu3aw6x69Wrl1/CAQAAAIA/eSxI6enp+vTTT1VQUKANGzZcs42CBAAAAKAh8liQ+vfvr/79+2vbtm3q16+fLly4oGbNml13yW8AAAAAaCi8flCs1WrVoEGDVFFRocTERLVp00bJycn+yAbUyDeOQGXut5odo8r+VXrlTYhmIfXvypHfOAIVb3aIGti8ebM2bdrkk32fOHFCkpSWluaT/UtSUlKS+6I6AACgerwWpNdff13/9V//pQkTJuiJJ55QamoqBQl1XlxcnNkRqu2M8UK65S0dTE5SdfGq38+9LzVv3tzsCAAAoBK8FqSAgABFRUXJYrEoNDRUERER/sjVIPjy3WhJstvtkiSbzeaT/dfnd6N9+S69r13NnpWVZXKSxicxMbHe/j8PAABqh9eCFB0drQULFuinn37SkiVL1KZNG3/kQiUUFBRI8l1BAgAAABobrwXppZde0tq1a9WjRw+Fh4dr1qxZ/sjVIPj63WhWGgAAAIDaFeDtDhaLRU6nUy6XSxUVFf7IBAAAAACm8LqC9OKLLyoyMlK9evXSvn37NG3aNM2fP98f2YA6ydfnlnG1MwAAAPN4LUj5+flauXKlpCufjZSSkuLzUEBjxtXOAAAAzOO1IJWUlOjSpUsKCwvT5cuXOcwOjR5XOgMAAGi4vBakRx55REOGDFGHDh2Ul5dXry+fDAAAAAC/xGtBevDBB9WnTx+dOXNGbdu21Q033OCPXAAAAADgdx6vYudwODR58mQ5HA5FRUXp9OnTmjlzphwOhz/zAQAAAIDfeCxIf/zjH3XHHXcoIiJCkjRw4EB17txZM2bM8Fc2AAAAAPArjwXpu+++029/+1tZLBZJUlBQkMaNG6czZ874LRwAAAAA+JPHc5CCgn5+U3BwsM/C+FtWVpby8vLMjlFt/vi8HF+Ki4urt9kBAADQMHksSNHR0dqyZYv69+/vvm3r1q268cYb/RLMH/Ly8nTgqyNyhtvMjlItloorP76ckz+YnKTqAortZkcAAAAAruOxIE2ZMkWTJk3SW2+9pbZt2+r777+XzWbT/Pnz/ZnP55zhNl2+bZDZMRqdJkc2mB0BAAAAuI7HghQZGal33nlH3333nc6dO6fWrVurZcuW/swGAAAAAH7l9XOQ2rRpozZt2vgjCwAAAGpo8+bN2rRpk8/2b7dfOUzeZvPdKQpJSUlKTEz02f6BX+K1IAEAAABXFRQUSPJtQQLM5LeC5HQ6NWPGDB0/flwhISHKzMxU+/bt3dvXrFmj1atXKygoSE8++aTuu+8+XbhwQQ888IDi4+MlSf3799eYMWP8FRkAAKDeSUxM9Onqy9Ur0GZlZflsDMBMXgvSnj17tGzZMpWWlrpve//996s80JYtW1RaWqrs7Gzl5uZq7ty5Wrx4sSTp/PnzWrFihdatW6eSkhKNHDlSPXv21JEjRzRo0CC9+OKLVR4PAAAAAKrKa0GaM2eOMjIy1KpVqxoNlJOTo969e0uSunbtqkOHDrm3HTx4UN26dVNISIhCQkIUHR2tY8eO6dChQzp8+LD+8z//UzabTdOmTdNNN91UoxwAAAAA4InXgtS6dWvdc889NR7I4XDIarW6vw4MDFR5ebmCgoLkcDjUtGlT97aIiAg5HA7deuut6ty5s+655x6tX79emZmZXpdzS0pKdPTo0UplKi4urt43g1pRXFxc6Z8VADQUVZmngLro6usn/j++Hq8tzVVbry29FqTmzZtr+vTpuu2222SxWCRJDz/8cJUHslqtKioqcn/tdDoVFBT0s9uKiorUtGlTdenSRWFhYZKkAQMGVOpY19DQUHXq1KlSmcLDwyVdrMJ3gdoUHh5e6Z8VgPqFF06eVWWeAuqiK6+fxP/HPyM8PFz6yewUjVdVX1t6mqsCvD2wbdu2uummm/Tjjz/q/PnzOn/+fOVT/puEhATt2rVLkpSbm+u+8IIkdenSRTk5OSopKVFhYaFOnjyp+Ph4TZs2TZ988okkae/evbr99turNTYAAAAAVIbXFaTx48drx44dOnHihGJiYtS/f/9qDTRgwADt2bNHKSkpcrlcmj17tpYtW6bo6Gjdf//9Gj16tEaOHCmXy6WJEycqNDRUkydPVkZGhlatWqWwsDBlZmZWa2wAAAAAqAyvBWnBggXKz89XQkKC/vu//1s5OTmaMmVKlQcKCAjQzJkzr7ktNjbW/fcRI0ZoxIgR12xv166dVqxYUeWxKstutyuguEBNjmzw2Rj4eQHFBbLbQ8yOAQAAAFzDa0H68ssvtXr1aknSmDFjrisxAAAAqJqsrCzl5eWZHaNaTpw4Ien/Pg+pvomLi6u32eEfXgtSeXm5nE6nAgIC5HK53BdqaAhsNpv+96dSXb5tkNlRGp0mRzbwCdwAgEYrLy9PXx/6h6KtFWZHqbJI15XXgpdPf2lykqr7xhFodgTUA14LUlJSklJTU3XnnXfq4MGDSkpK8kcuAACABi3aWqFpPRxmx2hUMvdbvd8JjZ7XgjR27Fj16tVLp06d0vDhw6+5+hwAAACAK+x2u3RBCtjh9ULRqG0XJHuYvVZ25bEgrV27VsnJyVqwYIH7sLojR45IkiZNmlQrgwMAAABAXeKxILVq1UqSdOutt15ze0M6BwkAAACoLTabTfmX8uXs6zQ7SqMTsCOg1s5v97j+17t3b0nSV199pWHDhrn//O1vf6uVgQEAAACgrvG4grRy5UotXrxY//rXv/Tpp5+6b//3zy4CAAAAgIbEY0EaNWqURo0apbfffltPPPGEPzMBAAAAgCm8XsUuJSVFGzZsUHl5uVwul86dO6fHH3/cH9n8IqDYriZHNpgdo1osZZckSa7gMJOTVF1AsV1SK7NjAAAAANfwWpDGjx+vW2+9VV9//bVCQ0MVFlb/Xox7EhcXZ3aEGrn6SdYdYutj0WhV759/AAAANDxeC5LL5dLMmTP1/PPP6+WXX9bIkSP9kcsv0tLSzI5QI1fzZ2VlmZwEAAAAaBi8fopVYGCgSkpKdOnSJVksFlVUVPgjFwAAAAD4ndeCNGrUKP35z39Wz549de+996pt27b+yAUAAAAAfuf1ELsHHnjA/feBAwfKarX6NBAAAAAAmMVrQVq9erVWr16t0tJS922bNm3yaaiGYvPmzT59rq5epMFX51IlJSUpMTHRJ/sGAAAA6iKvBen999/XkiVL1KxZM3/kQRU0b97c7AgAAABAg+K1IHXs2FGtW7dWYGCgP/I0KImJiazAAAAarR9//FEvvfSSZsyYwZt6AOoNrwXp17/+tfr376927drJ5XLJYrHo/fff90c2AABQjy1fvlwHDx7U8uXLNWnSJLPjAECleC1I2dnZeu2119S0aVN/5AEAAA3Ajz/+qI8//lgul0sff/yxxowZwyoSgHrB62W+W7ZsqTvuuEO33nqr+w8AAMAvWb58uVwulyTJ6XRq+fLlJicCgMrxuoJUWlqqIUOGqEOHDrJYLJKkBQsW+DwYAACovz777DOVlZVJksrKyvTpp59ymB2AesFrQUpNTVVkZKQ/sgAAgAZiwIAB2rRpk8rKyhQcHKzf/OY3ZkcCgErxWpDeffddrVq1yh9ZAABAAzFmzBh9/PHHkqSAgACNGTPG5EQAUDleC1KzZs20fPlyxcTEKCDgyilLvXr18nkwAABQf7Vo0UIDBw7U+vXrNXDgQC7QAKDe8FqQbrjhBh07dkzHjh1z30ZBAgAA3owZM0anT59m9QhAveK1IM2ZM0dff/218vLyFBMTo06dOvkjFwAAqOdatGihN954w+wYAFAlXgvSihUrtGHDBnXp0kXvvfeeBg4cqHHjxvkjGwAAAAD4ldeCtGHDBq1cuVJBQUEqKytTSkoKBQkAAABAg+S1ILlcLgUFXblbcHCwgoODfR4KAACgIbPb7TpfGKjM/VazozQq+YWButFuNzsG6jivBSkhIUFpaWnq3r27cnJy1K1bN3/kAgAAAAC/81iQvvzyS911112aOHGi9u7dq5MnT+qhhx5S3759/RgPAACg4bHZbAq/eFLTejjMjtKoZO63qonNZnYM1HEBnjZkZmaquLhYjz76qHr27KnRo0frnnvuUWlpqT/zAQAAAIDfeFxB6tWrlx588EGdO3dOiYmJkq6cj2SxWLR161a/BQQAAAAAf/FYkNLT05Wenq633npLf/jDH/yZCQAAAABM4fUiDcOGDdPSpUtVUlLivm38+PE+DQUAAAAAZvB4DtJVzzzzjBwOh1q0aOH+AwAAAAANkdcVpIiICE2cONEfWQAAAADAVF4LUocOHbRx40Z16tRJFotFkhQTE1PlgZxOp2bMmKHjx48rJCREmZmZat++vXv7mjVrtHr1agUFBenJJ5/UfffdJ7vdrmeffVaXL1/WTTfdpDlz5igsLKzKYwMAUB9lZWUpLy/PZ/u32+0qKCjw2f59rXnz5rL58JLNcXFxSktL89n+AdRNXgvS0aNHdfToUffXFotF77//fpUH2rJli0pLS5Wdna3c3FzNnTtXixcvliSdP39eK1as0Lp161RSUqKRI0eqZ8+eWrRokQYNGqSHHnpIS5YsUXZ2tn77299WeWwAAOqjvLw8HfjqiJzhvikBlrJLspTV34/vKDz3L/3vT77JH1Bs98l+AdR9XgvSihUramWgnJwc9e7dW5LUtWtXHTp0yL3t4MGD6tatm0JCQhQSEqLo6GgdO3ZMOTk5evzxxyVJffr00cKFCylIAIBGxRlu0+XbBpkdo9FpcmSD2REAmMRjQXr44Yfdh9T9/1avXl3lgRwOh6xWq/vrwMBAlZeXKygoSA6HQ02bNnVvi4iIkMPhuOb2iIgIFRYWeh2npKTkmhUvAADqkqrMU8XFxT5Og19SXFzss9cUxcXF3q+UBZ/w9c8V5qmtn63HgrRw4cIa7/zfWa1WFRUVub92Op0KCgr62W1FRUVq2rSp+/YmTZqoqKhIkZGRXscJDQ1Vp06dajU7AKBqeKPKs6rMU+Hh4ZIu+jYQPAoPD/fZa4rw8HBd9sme4Y2vf676ySe7RiVU9Wfraa7y+ObFzTff7PFPdSQkJGjXrl2SpNzcXMXHx7u3denSRTk5OSopKVFhYaFOnjyp+Ph4JSQkaOfOnZKkXbt2qXv37tUaGwAAAAAqw+s5SLVlwIAB2rNnj1JSUuRyuTR79mwtW7ZM0dHRuv/++zV69GiNHDlSLpdLEydOVGhoqJ588klNmTJFa9as0Q033KAFCxb4Ky4AAACARshvBSkgIEAzZ8685rbY2Fj330eMGKERI0Zcs71FixZ69913/ZIPAAAAADg/EAAAAAAMfltBAgAAVWO32xVQXMAlp00QUFwguz3E7BgATMAKEgAAAAAYWEECAKCOstls+t+fSvmgWBM0ObJBNpvN7BgATEBBAgCgDgsottfbQ+wsZZckSa7gMJOTVF1AsV1SK7NjADABBQkAgDoqLi7O7Ag1cuLECUlSh9j6WDRa1fvnH0D1UJAAAKij0tLSzI5QI1fzZ2VlmZwEACqPizQAAAAAgIGCBAAAAAAGDrEDAKCR2rx5szZt2uSz/V89B8lXhwomJSUpMTHRJ/sG0HhRkAAAgE80b97c7AgAUGUUJAAAGqnExERWYEz0jSNQmfutZseosn+VWiRJzUJcJiepum8cgYo3OwTqPAoSAACAn9XnS4ifMQ6dbHlLB5OTVF286vdzD/+gIAEAAPhZfb6EO5dvR0PHVewAAAAAwEBBAgAAAAADBQkAAAAADJyDBAAA0IDU98+3kviMK5iLggQAAIBK4/Ot0NBRkAAAABoQPt8KqBnOQQIAAAAAAwUJAAAAAAwcYgcAAADUlgtSwI56uAZx2fhvE1NTVN8FSTfXzq4oSAAAAEAtiIuLMztCtV29OmGHmzuYnKSabq6955+CBAAAANQCX1763NeuZs/KyjI5ifnq4fofAAAAAPgGBQkAAAAADBQkAAAAADBQkAAAAADAQEECAAAAAAMFCQAAAAAMFCQAAAAAMFCQAAAAAMBAQQIAAAAAAwUJAAAAAAwUJAAAAAAwUJAAAAAAwEBBAgAAAABDkL8Gunz5stLT01VQUKCIiAjNmzdPNpvtmvu8+eab2rFjh4KCgpSRkaEuXbroyJEjevzxx3XLLbdIklJTU5WUlOSv2AAAAAAaEb8VpFWrVik+Pl4TJkzQxo0btWjRIk2bNs29/fDhw9q3b5/Wrl2r77//XhMmTNC6det0+PBh/e53v9PYsWP9FRUAAABAI+W3Q+xycnLUu3dvSVKfPn20d+/e67b36tVLFotFbdq0UUVFhex2uw4dOqQdO3Zo1KhRysjIkMPh8FdkAAAAAI2MT1aQ1q5dq+XLl19zW/PmzdW0aVNJUkREhAoLC6/Z7nA4FBUV5f766n26dOmi5ORkde7cWYsXL9Zbb72lKVOmeBy7pKRER48erb1vBgCAWsQ8BaAuKi4uliT+fZKPClJycrKSk5OvuW38+PEqKiqSJBUVFSkyMvKa7Var1b396n2aNm2qAQMGuO87YMAAzZo16xfHDg0NVadOnWrj2wAAVBMTrGfMUwDqovDwcElqVP8+eZqr/HaIXUJCgnbu3ClJ2rVrl7p3737d9t27d8vpdOq7776T0+mUzWbTuHHjdPDgQUnS3r17dfvtt/srMgAAAIBGxm8XaUhNTdWUKVOUmpqq4OBgLViwQJI0f/58JSYmqkuXLurRo4cefvhhOZ1OTZ8+XZI0Y8YMzZo1S8HBwWrRooXXFSQAAAAAqC6Ly+VymR2iNh09erRRLQ0CQF3Ev8We8dwAqIvS0tIkSVlZWSYn8R9P/x7zQbEAAAAAYKAgAQAAAICBggQAAAAABgoSAAAAABgoSAAAAABgoCABAAAAgIGCBAAAAAAGChIAAAAAGChIAAAAAGCgIAEAAACAgYIEAAAAAAYKEgAAAAAYKEgAAAAAYKAgAQAAAICBggQAAAAABgoSAAAAABgoSAAAAABgoCABAAAAgIGCBAAAAAAGChIAAAAAGChIAAAAAGCgIAEAAACAIcjsAAAAAAC827x5szZt2uSTfZ84cUKSlJaW5pP9S1JSUpISExN9tv/aQkECAAAAGrnmzZubHaHOoCABAAAA9UBiYmK9WIGp7zgHCQAAAAAMFCQAAAAAMFCQAAAAAMBAQQIAAAAAAwUJAAAAAAwUJAAAAAAwUJAAAAAAwEBBAgAAAAADBQkAAAAADBQkAAAAADBQkAAAAADAEGR2gNpWUlKio0ePmh0DABq1kpISsyPUWcxTAFA3eJqrLC6Xy+XnLAAAAABQJ3GIHQAAAAAYKEgAAAAAYKAgAQAAAICBggQAAAAABgoSAAAAABga3GW+G5N//vOfevXVV7VixQqzo6AWDRs2TFarVZLUtm1bzZkzx+REqI6ysjJlZGTo22+/VWlpqZ588kndf//9kqTZs2crJiZGqampJqcEfIt5qmFinmoYmKc8oyDVU0uXLtX69esVFhZmdhTUopKSErlcLl5MNADr169XVFSUXnnlFV24cEFDhw5Vt27d9Nxzz+n06dMaN26c2REBn2KeapiYpxoO5inPOMSunoqOjtYbb7xhdgzUsmPHjunSpUsaO3asHnnkEeXm5podCdWUmJiop59+WpLkcrkUGBiooqIiTZgwQUOGDDE5HeB7zFMNE/NUw8E85RkFqZ564IEHFBTEAmBD06RJE40bN07vvvuuXnrpJT377LMqLy83OxaqISIiQlarVQ6HQ2lpaXrmmWfUrl073XnnnWZHA/yCeaphYp5qOJinPKMgAXVITEyMHnzwQVksFsXExCgqKkrnz583Oxaq6fvvv9cjjzyiIUOGaPDgwWbHAYAaY55qWJinfh4FCahD/vKXv2ju3LmSpLNnz8rhcOjGG280ORWq48cff9TYsWOVnp6u4cOHmx0HAGoF81TDwTzlGQUJqEOGDx+uwsJCpaamauLEiZo9ezaHqNRTb7/9ti5evKhFixZp9OjRGj16tC5fvmx2LACoEeaphoN5yjOLy+VymR0CAAAAAOoCVpAAAAAAwEBBAgAAAAADBQkAAAAADBQkAAAAADBQkAAAAADAQEECqunDDz/Uq6++WqXH9OvXTyUlJV7v98UXX2jixInVjXadXbt2aerUqbW2PwBA3cc8BVQPBQkAAAAADHyyF1BD7733njZu3KigoCD16NFD6enpunjxotLT0+VwOFRRUaGnn35ad999t/sxq1at0p49e7Rw4UJt27ZNK1euVHl5uSwWi958801JUn5+vh599FHZ7Xbdd999mjBhgo4fP67MzExJUlRUlGbPnq3w8HBNnz5dP/zwg86dO6d+/fpp4sSJOnnypDIyMhQWFqawsDA1a9bMlOcHAGAu5imgaihIQA3k5+friy++0OrVqxUUFKQJEyZo+/bt2rdvn+655x6NGTNGZ8+eVWpqqrZu3SpJWrFihY4eParXX39dgYGBOn36tJYsWaKwsDBNnz5du3fvVsuWLVVSUqJFixapoqJCffv21YQJE/Tiiy9q9uzZiouL09q1a/XOO+8oOTlZXbt2VXJyskpKStSnTx9NnDhR8+fPV1pamnr27KklS5bo1KlTJj9bAAB/Y54Cqo6CBNTA0aNH1bdvXwUHB0uSevTooRMnTujkyZMaPHiwJKlly5ayWq0qKCiQJO3du1eBgYEKDAyUJDVv3lxTpkxRRESETp06pa5du0qSOnTooJCQEElSUNCVX9WTJ0/qpZdekiSVlZXplltuUVRUlL766iv9/e9/l9VqVWlpqSTp9OnT6tKliyQpISGBiQcAGiHmKaDqOAcJqIFOnTrp4MGDKi8vl8vl0pdffqmYmBjFxsZq//79kqSzZ8/q4sWLioqKkiQtWrRIkZGRWrVqlQoLC5WVlaU//elPyszMVGhoqFwulyTJYrFcN15MTIzmzZunFStWKD09XX379tWHH36opk2basGCBRo7dqwuX74sl8ul2NhYHThwQJJ06NAh/zwhAIA6hXkKqDpWkIAaaN++vRISEpSamiqn06nu3burf//+uuuuu5SRkaFPPvlEly9f1syZM93vrknStGnTlJycrLvvvlsJCQl6+OGHFRQUpMjISJ07d05t27b92fFmzJihKVOmuI8Df/nllxUbG6vJkycrNzdXISEhat++vc6dO6epU6dqypQpevfdd2Wz2RQaGuqvpwUAUEcwTwFVZ3FdfRsAAAAAABo5DrEDAAAAAAMFCQAAAAAMFCQAAAAAMFCQAAAAAMBAQQIAAAAAAwUJAAAAAAwUJAAAAAAwUJAAAAAAwPD/ABqPADb4MLYUAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14,5), sharey=True)\n",
    "\n",
    "# plot average of daily IC values\n",
    "sns.boxplot(x='lookahead', y='ic_by_day',data=lr_metrics, ax=axes[0])\n",
    "axes[0].set_title('IC by Day')\n",
    "\n",
    "# plot IC across all predictions\n",
    "sns.boxplot(x='lookahead', y='ic',data=lr_metrics, ax=axes[1])\n",
    "axes[1].set_title('IC Overall')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "axes[1].set_ylabel('')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# top3 perofrmance in Train/Test Period Lengths\n",
    "(lr_metrics.groupby('lookahead', group_keys=False).apply(lambda x: x.nlargest(3, 'ic_by_day')))\n",
    "lr_metrics.to_csv(results_path / 'lin_reg_metrics.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Parameters: 108\n"
     ]
    }
   ],
   "source": [
    "# LightGBM Model Tuning\n",
    "def get_fi(model):\n",
    "    \"\"\"Return normalized feature importance as pd.Series\"\"\"\n",
    "    fi = model.feature_importance(importance_type='gain')\n",
    "    return (pd.Series(fi / fi.sum(), index=model.feature_name()))\n",
    "\n",
    "# Hyperparameter opt\n",
    "base_params = dict(boosting='gbdt', objective='regression', verbose=-1, device='gpu')\n",
    "\n",
    "# constraints on structure (depth) of each tree\n",
    "max_depths = [2, 3, 5, 7]\n",
    "num_leaves_opts = [2 ** i for i in max_depths]\n",
    "min_data_in_leaf_opts = [250, 500, 1000]\n",
    "\n",
    "# weight of each new tree in the ensemble\n",
    "learning_rate_ops = [.01, .1, .3]\n",
    "\n",
    "# random feature selection\n",
    "feature_fraction_opts = [.3, .6, .95]\n",
    "param_names = ['learning_rate', 'num_leaves', 'feature_fraction', 'min_data_in_leaf']\n",
    "cv_params = list(product(learning_rate_ops, num_leaves_opts, feature_fraction_opts, min_data_in_leaf_opts))\n",
    "n_params = len(cv_params)\n",
    "print(f'# Parameters: {n_params}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train configs: 6\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Period Lengths\n",
    "lookaheads = [1, 5, 21]\n",
    "label_dict = dict(zip(lookaheads, labels))\n",
    "train_lengths = [int(4.5 * 252), 252]\n",
    "test_lengths = [63]\n",
    "test_params = list(product(lookaheads, train_lengths, test_lengths))\n",
    "n = len(test_params)\n",
    "test_param_sample = np.random.choice(list(range(n)), size=int(n), replace=False)\n",
    "test_params = [test_params[i] for i in test_param_sample]\n",
    "print('Train configs:', len(test_params))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Categorical Variables\n",
    "categoricals = ['year', 'weekday', 'month']\n",
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]\n",
    "\n",
    "# Custom Loss Function: Information Coefficient\n",
    "def ic_lgbm(preds, train_data):\n",
    "    \"\"\"Custom IC eval metric for lightgbm\"\"\"\n",
    "    is_higher_better = True\n",
    "    return 'ic', spearmanr(preds, train_data.get_label())[0], is_higher_better\n",
    "\n",
    "# Run Cross-Validation\n",
    "lgb_store = Path(results_path / 'tuning_lgb.h5')\n",
    "labels = sorted(data.filter(like='fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()\n",
    "label_dict = dict(zip(lookaheads, labels))\n",
    "num_iterations = [10, 25, 50, 75] + list(range(100, 501, 50))\n",
    "num_boost_round = num_iterations[-1]\n",
    "metric_cols = (param_names + ['t', 'daily_ic_mean', 'daily_ic_mean_n',\n",
    "                              'daily_ic_median', 'daily_ic_median_n'] + [str(n) for n in num_iterations])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookahead:  1 | Train: 1134 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:49 ( 49) |  0.30 |   4 | 95% | 1000 |   2.07% |  1.55% |  300 |  2.09% |  500\n",
      "\t  1 | 00:01:39 ( 50) |  0.01 |   4 | 60% |  500 |   1.28% |  0.85% |  100 |  0.76% |  200\n",
      "\t  2 | 00:02:26 ( 47) |  0.10 |   4 | 60% |  500 |   3.07% |  2.00% |  450 |  1.80% |  450\n",
      "\t  3 | 00:05:26 (180) |  0.10 | 128 | 95% |  250 |   3.35% |  1.63% |   50 |  1.96% |  250\n",
      "\t  4 | 00:06:24 ( 57) |  0.01 |   8 | 30% |  500 |   1.01% |  1.27% |  350 |  1.01% |  350\n",
      "\t  5 | 00:07:19 ( 55) |  0.10 |   8 | 30% |  250 |   2.13% |  1.42% |  100 |  1.61% |  200\n",
      "\t  6 | 00:10:21 (182) |  0.10 | 128 | 95% |  500 |   3.50% |  1.37% |   50 |  1.61% |  450\n",
      "\t  7 | 00:13:25 (184) |  0.10 | 128 | 60% |  250 |   3.53% |  1.06% |  100 |  1.63% |  350\n",
      "\t  8 | 00:14:24 ( 59) |  0.10 |   8 | 30% | 1000 |   2.97% |  1.56% |  450 |  1.89% |  450\n",
      "\t  9 | 00:15:42 ( 78) |  0.01 |   8 | 30% | 1000 |   1.57% |  1.37% |  400 |  1.01% |  500\n",
      "\t 10 | 00:17:05 ( 83) |  0.30 |  32 | 95% | 1000 |   4.06% |  1.68% |   25 |  1.50% |  100\n",
      "\t 11 | 00:17:58 ( 53) |  0.10 |   4 | 30% |  250 |   3.41% |  1.56% |  350 |  1.70% |  250\n",
      "\t 12 | 00:18:55 ( 56) |  0.30 |   8 | 30% | 1000 |   3.79% |  1.48% |   25 |  1.53% |   25\n",
      "\t 13 | 00:19:54 ( 60) |  0.10 |   8 | 95% |  250 |   3.69% |  1.81% |  500 |  1.69% |  300\n",
      "\t 14 | 00:21:39 (105) |  0.01 |  32 | 30% |  250 |   1.74% |  1.38% |   25 |  1.37% |   25\n",
      "\t 15 | 00:22:37 ( 57) |  0.01 |   4 | 30% |  250 |   0.78% |  0.95% |  500 |  1.31% |  100\n",
      "\t 16 | 00:23:32 ( 55) |  0.30 |   4 | 30% |  250 |   4.04% |  1.78% |  250 |  2.35% |  200\n",
      "\t 17 | 00:25:26 (115) |  0.01 |  32 | 95% | 1000 |   2.91% |  1.55% |  500 |  2.05% |  450\n",
      "\t 18 | 00:26:29 ( 62) |  0.30 |   8 | 30% |  250 |   3.86% |  1.98% |   50 |  2.04% |   75\n",
      "\t 19 | 00:27:32 ( 63) |  0.10 |   8 | 95% | 1000 |   3.46% |  2.26% |  500 |  2.17% |  450\n",
      "\t 20 | 00:30:38 (186) |  0.30 | 128 | 60% |  500 |   3.58% |  1.79% |   10 |  1.99% |   25\n",
      "\t 21 | 00:32:08 ( 90) |  0.30 |  32 | 30% |  500 |   2.74% |  1.52% |  150 |  1.80% |  500\n",
      "\t 22 | 00:33:13 ( 65) |  0.01 |   8 | 60% |  250 |   2.00% |  1.25% |  400 |  1.22% |   75\n",
      "\t 23 | 00:37:03 (231) |  0.01 | 128 | 60% |  500 |   2.50% |  1.68% |  400 |  2.24% |  200\n",
      "\t 24 | 00:40:27 (204) |  0.10 | 128 | 60% |  500 |   3.18% |  1.62% |  400 |  1.52% |  500\n",
      "\t 25 | 00:42:06 ( 99) |  0.30 |  32 | 30% | 1000 |   3.96% |  1.64% |  100 |  1.86% |  450\n",
      "\t 26 | 00:46:03 (237) |  0.10 | 128 | 95% | 1000 |   3.67% |  1.39% |   50 |  1.67% |   50\n",
      "\t 27 | 00:48:14 (130) |  0.01 |  32 | 60% |  500 |   2.45% |  1.51% |  450 |  1.56% |  350\n",
      "\t 28 | 00:49:17 ( 63) |  0.10 |   4 | 95% | 1000 |   3.19% |  1.62% |  400 |  1.86% |  400\n",
      "\t 29 | 00:53:26 (249) |  0.30 | 128 | 95% | 1000 |   4.08% |  1.40% |   25 |  1.67% |   25\n",
      "\t 30 | 00:54:30 ( 65) |  0.30 |   4 | 95% |  250 |   3.96% |  1.90% |  250 |  1.91% |  150\n",
      "\t 31 | 00:55:46 ( 75) |  0.01 |   8 | 95% |  250 |   2.65% |  1.70% |  500 |  1.67% |  300\n",
      "\t 32 | 01:00:17 (271) |  0.01 | 128 | 60% |  250 |   1.96% |  1.53% |  500 |  1.92% |  400\n",
      "\t 33 | 01:04:23 (247) |  0.30 | 128 | 60% | 1000 |   3.57% |  1.52% |  300 |  1.74% |  400\n",
      "\t 34 | 01:05:41 ( 78) |  0.01 |   8 | 30% |  250 |   0.89% |  1.24% |  350 |  1.11% |  500\n",
      "\t 35 | 01:10:09 (268) |  0.01 | 128 | 95% |  250 |   3.54% |  1.92% |  450 |  1.56% |  450\n",
      "\t 36 | 01:12:00 (111) |  0.10 |  32 | 95% | 1000 |   3.98% |  1.89% |   25 |  1.67% |   25\n",
      "\t 37 | 01:15:10 (190) |  0.10 | 128 | 30% | 1000 |   3.39% |  1.41% |   25 |  1.28% |  500\n",
      "\t 38 | 01:18:33 (202) |  0.01 | 128 | 30% |  500 |   2.51% |  1.72% |  250 |  1.75% |  150\n",
      "\t 39 | 01:19:21 ( 48) |  0.10 |   4 | 95% |  250 |   3.17% |  1.51% |  400 |  1.43% |   25\n",
      "\t 40 | 01:20:18 ( 57) |  0.01 |   4 | 60% | 1000 |   1.63% |  0.92% |   50 |  0.83% |  200\n"
     ]
    }
   ],
   "source": [
    "for lookahead, train_length, test_length in test_params:\n",
    "    # randomized grid search\n",
    "    cvp = np.random.choice(list(range(n_params)), size=int(n_params / 2), replace=False)\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "\n",
    "    # set up cross-validation\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    print(f'Lookahead: {lookahead:2.0f} | Train: {train_length:3.0f} | Test: {test_length:2.0f} | '\n",
    "          f'Params: {len(cv_params_):3.0f} | Train configs: {len(test_params)}')\n",
    "\n",
    "    # time-series cross-validation\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits, lookahead=lookahead, test_period_length=test_length,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    outcome_data = data.loc[:, features + [label]].dropna()\n",
    "\n",
    "    # binary dataset\n",
    "    lgb_data = lgb.Dataset(data=outcome_data.drop(label, axis=1), label=outcome_data[label],\n",
    "                           categorical_feature=categoricals, free_raw_data=False)\n",
    "    T = 0\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "\n",
    "    # iterate over (shuffled) hyperparameter combinations\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        key = f'{lookahead}/{train_length}/{test_length}/' + '/'.join([str(p) for p in param_vals])\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        params.update(base_params)\n",
    "\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "\n",
    "        # iterate over folds\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "\n",
    "            # select train subset\n",
    "            lgb_train = lgb_data.subset(used_indices=train_idx.tolist(), params=params).construct()\n",
    "\n",
    "            # train model for num_boost_round\n",
    "            model = lgb.train(params=params, train_set=lgb_train, num_boost_round=num_boost_round,\n",
    "                              verbose_eval=False)\n",
    "            # log feature importance\n",
    "            if i == 0:\n",
    "                fi = get_fi(model).to_frame()\n",
    "            else:\n",
    "                fi[i] = get_fi(model)\n",
    "\n",
    "            # capture predictions\n",
    "            test_set = outcome_data.iloc[test_idx, :]\n",
    "            X_test = test_set.loc[:, model.feature_name()]\n",
    "            y_test = test_set.loc[:, label]\n",
    "            y_pred = {str(n): model.predict(X_test, num_iteration=n) for n in num_iterations}\n",
    "\n",
    "            # record predictions for each fold\n",
    "            cv_preds.append(y_test.to_frame('y_test').assign(**y_pred).assign(i=i))\n",
    "\n",
    "        # combine fold results\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "        predictions.append(cv_preds)\n",
    "\n",
    "        # compute IC per day\n",
    "        by_day = cv_preds.groupby(level='date')\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "\n",
    "        # compute IC across all predictions\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0] for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "\n",
    "        # collect metrics\n",
    "        metrics = pd.Series(list(param_vals) + [t, daily_ic_mean.max(), daily_ic_mean_n, daily_ic_median.max(),\n",
    "                             daily_ic_median_n] + ic, index=metric_cols)\n",
    "        msg = f'\\t{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"learning_rate\"]:5.2f} | '\n",
    "        msg += f'{params[\"num_leaves\"]:3.0f} | {params[\"feature_fraction\"]:3.0%} | '\n",
    "        msg += f'{params[\"min_data_in_leaf\"]:4.0f} | '\n",
    "        msg += f' {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {daily_ic_mean_n: 4.0f} | '\n",
    "        msg += f'{ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "\n",
    "        # persist results for given CV run and hyperparameter combination\n",
    "        metrics.to_hdf(lgb_store, 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf(lgb_store, 'daily_ic/' + key)\n",
    "        fi.T.describe().T.assign(**params).to_hdf(lgb_store, 'fi/' + key)\n",
    "        cv_preds.to_hdf(lgb_store, 'predictions/' + key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "key"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CatBoost Model Tuning\n",
    "\n",
    "# Hyperparameter Opts\n",
    "param_names = ['max_depth', 'min_child_samples']\n",
    "\n",
    "max_depth_opts = [3, 5, 7, 9]\n",
    "min_child_samples_opts = [20, 250, 500]\n",
    "cv_params = list(product(max_depth_opts, min_child_samples_opts))\n",
    "n_params = len(cv_params)\n",
    "\n",
    "# Train/Test Period Lengths\n",
    "lookaheads = [1, 5, 21]\n",
    "label_dict = dict(zip(lookaheads, labels))\n",
    "train_lengths = [int(4.5 * 252), 252]\n",
    "test_lengths = [63]\n",
    "test_params = list(product(lookaheads, train_lengths, test_lengths))\n",
    "\n",
    "# Custom Loss Function\n",
    "class CatBoostIC(object):\n",
    "    \"\"\"Custom IC eval metric for CatBoost\"\"\"\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        # Returns whether great values of metric are better\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        target = np.array(target)\n",
    "        approxes = np.array(approxes).reshape(-1)\n",
    "        rho = spearmanr(approxes, target)[0]\n",
    "        return rho, 1\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        # Returns final value of metric based on error and weight\n",
    "        return error\n",
    "\n",
    "# Run Cross-Validation\n",
    "cb_store = Path(results_path / 'tuning_catboost.h5')\n",
    "num_iterations = [10, 25, 50, 75] + list(range(100, 1001, 100))\n",
    "num_boost_round = num_iterations[-1]\n",
    "metric_cols = (param_names + ['t', 'daily_ic_mean', 'daily_ic_mean_n',\n",
    "                              'daily_ic_median', 'daily_ic_median_n'] + [str(n) for n in num_iterations])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_iterations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for lookahead, train_length, test_length in test_params:\n",
    "    cvp = np.random.choice(list(range(n_params)), size=int(n_params / 1), replace=False)\n",
    "    print(f'cvp: {cvp}')\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "    print(f'cv_params_: {cv_params_}\\n')\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    print(f'Lookahead: {lookahead:2.0f} | Train: {train_length:3.0f} | '\n",
    "          f'Test: {test_length:2.0f} | Params: {len(cv_params_):3.0f} | Train configs: {len(test_params)}')\n",
    "\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits, lookahead=lookahead, test_period_length=test_length,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    outcome_data = data.loc[:, features + [label]].dropna()\n",
    "    cat_cols_idx = [outcome_data.columns.get_loc(c) for c in categoricals]\n",
    "    catboost_data = Pool(label=outcome_data[label], data=outcome_data.drop(label, axis=1),\n",
    "                         cat_features=cat_cols_idx)\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "    key = f'{lookahead}/{train_length}/{test_length}'\n",
    "    T = 0\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        params['task_type'] = 'GPU'\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "            train_set = catboost_data.slice(train_idx.tolist())\n",
    "\n",
    "            model = CatBoostRegressor(**params)\n",
    "            model.fit(X=train_set, verbose_eval=False)\n",
    "\n",
    "            test_set = outcome_data.iloc[test_idx, :]\n",
    "            X_test = test_set.loc[:, model.feature_names_]\n",
    "            y_test = test_set.loc[:, label]\n",
    "            y_pred = {str(n): model.predict(X_test, ntree_end=n) for n in num_iterations}\n",
    "            cv_preds.append(y_test.to_frame('y_test').assign(**y_pred).assign(i=i))\n",
    "\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "\n",
    "        predictions.append(cv_preds)\n",
    "        by_day = cv_preds.groupby(level='date')\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0] for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "        metrics = pd.Series(list(param_vals) + [t, daily_ic_mean.max(), daily_ic_mean_n,\n",
    "                             daily_ic_median.max(), daily_ic_median_n] + ic, index=metric_cols)\n",
    "        msg = f'{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"max_depth\"]:3.0f} | '\n",
    "        msg += f'{params[\"min_child_samples\"]:4.0f} | {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | '\n",
    "        msg += f'{daily_ic_mean_n: 4.0f} | {ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "        metrics.to_hdf(cb_store, 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf(cb_store, 'daily_ic/' + key)\n",
    "        cv_preds.to_hdf(cb_store, 'predictions/' + key)\n",
    "\n",
    "\n",
    "print(\"results: \" , pd.concat([metrics.tail(), cv_preds]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}